{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized/blob/main/data/train_prefs-00000-of-00001-17309c769bfe5733.parquet\n",
    "import pandas as pd\n",
    "df = pd.read_parquet(\"train_prefs-00000-of-00001-17309c769bfe5733.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rwkv.utils import PIPELINE\n",
    "from rwkv.model import RWKV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RWKV_JIT_ON 1 RWKV_CUDA_ON 0 RESCALE_LAYER 0\n",
      "\n",
      "Loading D:/models/rwkv/RWKV-5-World-0.4B-v2-20231113-ctx4096.pth ...\n",
      "Model detected: v5.2\n",
      "Strategy: (total 24+1=25 layers)\n",
      "* cuda [bfloat16, bfloat16], store 25 layers\n",
      "0-cuda-bfloat16-bfloat16 1-cuda-bfloat16-bfloat16 2-cuda-bfloat16-bfloat16 3-cuda-bfloat16-bfloat16 4-cuda-bfloat16-bfloat16 5-cuda-bfloat16-bfloat16 6-cuda-bfloat16-bfloat16 7-cuda-bfloat16-bfloat16 8-cuda-bfloat16-bfloat16 9-cuda-bfloat16-bfloat16 10-cuda-bfloat16-bfloat16 11-cuda-bfloat16-bfloat16 12-cuda-bfloat16-bfloat16 13-cuda-bfloat16-bfloat16 14-cuda-bfloat16-bfloat16 15-cuda-bfloat16-bfloat16 16-cuda-bfloat16-bfloat16 17-cuda-bfloat16-bfloat16 18-cuda-bfloat16-bfloat16 19-cuda-bfloat16-bfloat16 20-cuda-bfloat16-bfloat16 21-cuda-bfloat16-bfloat16 22-cuda-bfloat16-bfloat16 23-cuda-bfloat16-bfloat16 24-cuda-bfloat16-bfloat16 \n",
      "emb.weight                       bf16      cpu  65536  1024 \n",
      "blocks.0.ln1.weight              bf16   cuda:0   1024       \n",
      "blocks.0.ln1.bias                bf16   cuda:0   1024       \n",
      "blocks.0.ln2.weight              bf16   cuda:0   1024       \n",
      "blocks.0.ln2.bias                bf16   cuda:0   1024       \n",
      "blocks.0.att.time_mix_k          bf16   cuda:0   1024       \n",
      "blocks.0.att.time_mix_v          bf16   cuda:0   1024       \n",
      "blocks.0.att.time_mix_r          bf16   cuda:0   1024       \n",
      "blocks.0.att.time_mix_g          bf16   cuda:0   1024       \n",
      "blocks.0.att.time_decay           f32   cuda:0     16    64 \n",
      "blocks.0.att.time_first           f32   cuda:0     16    64 \n",
      "blocks.0.att.receptance.weight   bf16   cuda:0   1024  1024 \n",
      "blocks.0.att.key.weight          bf16   cuda:0   1024  1024 \n",
      "blocks.0.att.value.weight        bf16   cuda:0   1024  1024 \n",
      "blocks.0.att.output.weight       bf16   cuda:0   1024  1024 \n",
      "blocks.0.att.gate.weight         bf16   cuda:0   1024  1024 \n",
      "blocks.0.att.ln_x.weight          f32   cuda:0   1024       \n",
      "blocks.0.att.ln_x.bias            f32   cuda:0   1024       \n",
      "blocks.0.ffn.time_mix_k          bf16   cuda:0   1024       \n",
      "blocks.0.ffn.time_mix_r          bf16   cuda:0   1024       \n",
      "blocks.0.ffn.key.weight          bf16   cuda:0   1024  3584 \n",
      "blocks.0.ffn.receptance.weight   bf16   cuda:0   1024  1024 \n",
      "blocks.0.ffn.value.weight        bf16   cuda:0   3584  1024 \n",
      "....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "blocks.23.ln1.weight             bf16   cuda:0   1024       \n",
      "blocks.23.ln1.bias               bf16   cuda:0   1024       \n",
      "blocks.23.ln2.weight             bf16   cuda:0   1024       \n",
      "blocks.23.ln2.bias               bf16   cuda:0   1024       \n",
      "blocks.23.att.time_mix_k         bf16   cuda:0   1024       \n",
      "blocks.23.att.time_mix_v         bf16   cuda:0   1024       \n",
      "blocks.23.att.time_mix_r         bf16   cuda:0   1024       \n",
      "blocks.23.att.time_mix_g         bf16   cuda:0   1024       \n",
      "blocks.23.att.time_decay          f32   cuda:0     16    64 \n",
      "blocks.23.att.time_first          f32   cuda:0     16    64 \n",
      "blocks.23.att.receptance.weight  bf16   cuda:0   1024  1024 \n",
      "blocks.23.att.key.weight         bf16   cuda:0   1024  1024 \n",
      "blocks.23.att.value.weight       bf16   cuda:0   1024  1024 \n",
      "blocks.23.att.output.weight      bf16   cuda:0   1024  1024 \n",
      "blocks.23.att.gate.weight        bf16   cuda:0   1024  1024 \n",
      "blocks.23.att.ln_x.weight         f32   cuda:0   1024       \n",
      "blocks.23.att.ln_x.bias           f32   cuda:0   1024       \n",
      "blocks.23.ffn.time_mix_k         bf16   cuda:0   1024       \n",
      "blocks.23.ffn.time_mix_r         bf16   cuda:0   1024       \n",
      "blocks.23.ffn.key.weight         bf16   cuda:0   1024  3584 \n",
      "blocks.23.ffn.receptance.weight  bf16   cuda:0   1024  1024 \n",
      "blocks.23.ffn.value.weight       bf16   cuda:0   3584  1024 \n",
      "ln_out.weight                    bf16   cuda:0   1024       \n",
      "ln_out.bias                      bf16   cuda:0   1024       \n",
      "head.weight                      bf16   cuda:0   1024 65536 \n"
     ]
    }
   ],
   "source": [
    "model = RWKV(\"D:/models/rwkv/RWKV-5-World-0.4B-v2-20231113-ctx4096.pth\", \"cuda bf16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PIPELINE(model, \"rwkv_vocab_v20230424\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([261, 24281, 59], [261, 53671, 59])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"\\n\\nUser:\"), tokenizer.encode(\"\\n\\nResponse:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(100)\n",
    "train_percent = 0.8\n",
    "train_valid_percent = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = []\n",
    "validset = []\n",
    "testset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_base_prob(prompt_tokens, chosen_tokens):\n",
    "    global tokenizer\n",
    "    full_logits_chosen, _ = tokenizer.model.forward(prompt_tokens + chosen_tokens[:-1], None, full_output=True)\n",
    "    chosen_logits = full_logits_chosen[-len(chosen_tokens):]\n",
    "    chosen_loss = (F.log_softmax(chosen_logits, dim=-1))[torch.arange(len(chosen_tokens)), chosen_tokens]\n",
    "    return float(torch.sum(chosen_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\Python311\\Lib\\site-packages\\rwkv\\model.py:1138: UserWarning: operator () profile_node %157 : int = prim::profile_ivalue(%155)\n",
      " does not have profile information (Triggered internally at ..\\third_party\\nvfuser\\csrc\\graph_fuser.cpp:108.)\n",
      "  x, state[i*3+0], state[i*3+1] = ATT(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1845.47900390625 -768.1392822265625\n",
      "-927.13330078125 -1809.7193603515625\n",
      "-367.13763427734375 -184.26104736328125\n",
      "-151.35646057128906 -566.4130859375\n",
      "-532.8018798828125 -166.65216064453125\n",
      "-909.8840942382812 -844.625732421875\n",
      "-605.8050537109375 -33.850189208984375\n",
      "-181.65533447265625 -92.8620376586914\n",
      "-169.68191528320312 -398.36627197265625\n",
      "-1132.143798828125 -482.20489501953125\n",
      "-84.56585693359375 -41.13652801513672\n",
      "-148.7683868408203 -19.554271697998047\n",
      "-1841.4710693359375 -1194.8499755859375\n",
      "-905.9949340820312 -375.1104736328125\n",
      "-34.30028533935547 -25.615936279296875\n",
      "-282.25030517578125 -200.34786987304688\n",
      "-56.40519714355469 -105.28010559082031\n",
      "-29.12896156311035 -73.40998077392578\n",
      "-34.48490524291992 -450.10784912109375\n",
      "-115.04679870605469 -16.300830841064453\n",
      "-58.02155685424805 -215.5607147216797\n",
      "-936.566162109375 -43.03139877319336\n",
      "-85.80197143554688 -28.40114974975586\n",
      "-7.36306619644165 -172.81602478027344\n",
      "-445.5924072265625 -836.9470825195312\n",
      "-79.41017150878906 -31.255094528198242\n",
      "-107.93856811523438 -221.1228790283203\n",
      "-68.01826477050781 -84.31118774414062\n",
      "-636.9298706054688 -382.9815673828125\n",
      "-489.70709228515625 -584.1371459960938\n",
      "-1535.041259765625 -223.1104736328125\n",
      "-81.448486328125 -78.74626159667969\n",
      "-203.51654052734375 -156.41885375976562\n",
      "-310.717041015625 -273.0664978027344\n",
      "-754.9442749023438 -422.11151123046875\n",
      "-1122.791259765625 -445.7442626953125\n",
      "-754.1478881835938 -205.11029052734375\n",
      "-462.1377868652344 -110.547119140625\n",
      "-830.4510498046875 -655.3875732421875\n",
      "-518.53271484375 -230.5809326171875\n",
      "-373.150634765625 -212.56100463867188\n",
      "-22.96632957458496 -193.77957153320312\n",
      "-1287.295166015625 -383.8680725097656\n",
      "-180.25660705566406 -399.34698486328125\n",
      "-506.81243896484375 -472.50341796875\n",
      "-70.82559204101562 -121.40625\n",
      "-768.91015625 -619.7981567382812\n",
      "-776.9923706054688 -960.3790283203125\n",
      "-174.3426055908203 -309.96942138671875\n",
      "-121.9245376586914 -89.02584838867188\n",
      "-11.8389892578125 -16.540027618408203\n",
      "-947.7423706054688 -424.7830810546875\n",
      "-728.386474609375 -574.8724365234375\n",
      "-875.1705932617188 -23.26849365234375\n",
      "-45.10035705566406 -39.10715866088867\n",
      "-30.47852325439453 -214.89697265625\n",
      "-547.5411987304688 -145.69052124023438\n",
      "-821.2927856445312 -348.41217041015625\n",
      "-482.2662658691406 -337.48724365234375\n",
      "-1255.40234375 -1202.708984375\n",
      "-74.42510223388672 -170.9370574951172\n",
      "-118.74118041992188 -236.79232788085938\n",
      "-7.6400837898254395 -127.30828857421875\n",
      "-90.37471008300781 -91.62165832519531\n",
      "-455.8435974121094 -214.2702178955078\n",
      "-21.605239868164062 -43.558624267578125\n",
      "-36.43913269042969 -18.039827346801758\n",
      "-175.30612182617188 -550.0987548828125\n",
      "-394.2469177246094 -348.6104736328125\n",
      "-360.7253112792969 -269.24468994140625\n",
      "-38.09058380126953 -240.60940551757812\n",
      "-95.90996551513672 -62.363155364990234\n",
      "-138.4346923828125 -42.19160461425781\n",
      "-64.18962097167969 -508.38458251953125\n",
      "-100.02398681640625 -22.84848403930664\n",
      "-14.128366470336914 -52.19739532470703\n",
      "-587.9467163085938 -750.19873046875\n",
      "-745.37890625 -442.70892333984375\n",
      "-50.84618377685547 -55.843990325927734\n",
      "-24.30878257751465 -34.096946716308594\n",
      "-394.6376647949219 -167.25814819335938\n",
      "-292.97607421875 -14.00697135925293\n",
      "-696.9076538085938 -710.873779296875\n",
      "-227.8721466064453 -50.65618133544922\n",
      "-518.9602661132812 -236.17649841308594\n",
      "-574.8671875 -309.03570556640625\n",
      "-171.40972900390625 -307.4994812011719\n",
      "-564.845703125 -159.80955505371094\n",
      "-154.2318115234375 -91.58879852294922\n",
      "-1350.2183837890625 -332.52838134765625\n",
      "-11.56789779663086 -30.067625045776367\n",
      "-1077.70849609375 -691.5721435546875\n",
      "-132.88638305664062 -58.84774398803711\n",
      "-54.440040588378906 -343.3310546875\n",
      "-952.7488403320312 -359.42626953125\n",
      "-618.9912719726562 -689.911865234375\n",
      "-370.71783447265625 -105.32681274414062\n",
      "-124.71980285644531 -62.64079284667969\n",
      "-90.15499877929688 -133.569091796875\n",
      "-59.79052734375 -11.739153861999512\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    prompt_str = str(df.iloc[i].prompt).strip()\n",
    "    chosen_str = str(df.iloc[i].chosen[1][\"content\"]).strip().replace(\"\\n\\n\", \"\\n\")\n",
    "    reject_str = str(df.iloc[i].rejected[1][\"content\"]).strip().replace(\"\\n\\n\", \"\\n\")\n",
    "    h = random.random()\n",
    "    if h < 0.8:\n",
    "        prompt_str = \"User: \" + prompt_str + \"\\n\\nAssistant:\" # Helpfulness optimization\n",
    "        chosen_str = ' ' + chosen_str + \"\\n\\n\"\n",
    "        reject_str = ' ' + reject_str + \"\\n\\n\"\n",
    "    elif h<0.9:\n",
    "        prompt_str = \"Question: \" + prompt_str + \"\\n\\nAnswer:\" # Factuality\n",
    "        chosen_str = ' ' + chosen_str + \"\\n\\n\"\n",
    "        reject_str = ' ' + reject_str + \"\\n\\n\"\n",
    "    else:\n",
    "        prompt_str = \"Input: \" + prompt_str + \"\\n\\nResponse:\" # Instruction-following\n",
    "        chosen_str = ' ' + chosen_str + \"\\n\\n\"\n",
    "        reject_str = ' ' + reject_str + \"\\n\\n\"\n",
    "    prompt_tokens = tokenizer.encode(prompt_str)\n",
    "    chosen_tokens = tokenizer.encode(chosen_str)\n",
    "    reject_tokens = tokenizer.encode(reject_str)\n",
    "\n",
    "    chosen_base_prob = compute_base_prob(prompt_tokens, chosen_tokens)\n",
    "    reject_base_prob = compute_base_prob(prompt_tokens, reject_tokens)\n",
    "\n",
    "    print(chosen_base_prob, reject_base_prob)\n",
    "    # prompt_chosen_mask = [0] * (len(prompt_tokens)-1) + [1] * len(chosen_tokens)\n",
    "    # prompt_reject_mask = [0] * (len(prompt_tokens)-1) + [1] * len(reject_tokens)\n",
    "    h = random.random()\n",
    "    if h < train_percent:\n",
    "        trainset.append((prompt_tokens, chosen_tokens, reject_tokens, chosen_base_prob, reject_base_prob))\n",
    "    elif h < train_valid_percent:\n",
    "        validset.append((prompt_tokens, chosen_tokens, reject_tokens, chosen_base_prob, reject_base_prob))\n",
    "    else:\n",
    "        testset.append((prompt_tokens, chosen_tokens, reject_tokens, chosen_base_prob, reject_base_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(trainset, \"trainset.save\")\n",
    "torch.save(validset, \"validset.save\")\n",
    "torch.save(testset, \"testset.save\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
